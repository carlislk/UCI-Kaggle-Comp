{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 532)\n",
      "(60000, 1)\n",
      "(40000, 532)\n"
     ]
    }
   ],
   "source": [
    "# Iris Data\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import OneClassSVM\n",
    "import sklearn.linear_model as lm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Data Files\n",
    "\n",
    "# load data\n",
    "df_train_1 = pd.read_csv('./data/kaggle.X1.train.txt', header=None)\n",
    "df_train_2 = pd.read_csv('./data/kaggle.X2.train.txt', header=None)\n",
    "df_train_Y = pd.read_csv('./data/kaggle.Y.train.txt', header=None)\n",
    "df_test_1 = pd.read_csv('./data/kaggle.X1.test.txt', header=None)\n",
    "df_test_2 = pd.read_csv('./data/kaggle.X2.test.txt', header=None)\n",
    "\n",
    "# Combine Train Data \n",
    "df_train_X = pd.concat([df_train_1, df_train_2], axis=1)\n",
    "\n",
    "# Combine Test Data \n",
    "df_test_X = pd.concat([df_test_1, df_test_2], axis=1)\n",
    "\n",
    "\n",
    "# Create Numpy Arrays\n",
    "X_train = df_train_X.values\n",
    "y_train = df_train_Y.values\n",
    "X_test = df_test_X.values\n",
    "\n",
    "# Use Only X1\n",
    "# X_train = df_train_1.values\n",
    "# X_test = df_test_1.values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-rmse:0.833439\n",
      "[1]\tvalidation_0-rmse:0.822915\n",
      "[2]\tvalidation_0-rmse:0.812914\n",
      "[3]\tvalidation_0-rmse:0.802847\n",
      "[4]\tvalidation_0-rmse:0.793822\n",
      "[5]\tvalidation_0-rmse:0.784951\n",
      "[6]\tvalidation_0-rmse:0.776040\n",
      "[7]\tvalidation_0-rmse:0.767773\n",
      "[8]\tvalidation_0-rmse:0.759897\n",
      "[9]\tvalidation_0-rmse:0.752396\n",
      "[10]\tvalidation_0-rmse:0.745540\n",
      "[11]\tvalidation_0-rmse:0.738729\n",
      "[12]\tvalidation_0-rmse:0.732228\n",
      "[13]\tvalidation_0-rmse:0.726133\n",
      "[14]\tvalidation_0-rmse:0.720053\n",
      "[15]\tvalidation_0-rmse:0.714523\n",
      "[16]\tvalidation_0-rmse:0.709065\n",
      "[17]\tvalidation_0-rmse:0.703969\n",
      "[18]\tvalidation_0-rmse:0.698853\n",
      "[19]\tvalidation_0-rmse:0.694282\n",
      "[20]\tvalidation_0-rmse:0.689765\n",
      "[21]\tvalidation_0-rmse:0.685284\n",
      "[22]\tvalidation_0-rmse:0.681479\n",
      "[23]\tvalidation_0-rmse:0.677577\n",
      "[24]\tvalidation_0-rmse:0.673950\n",
      "[25]\tvalidation_0-rmse:0.670418\n",
      "[26]\tvalidation_0-rmse:0.666822\n",
      "[27]\tvalidation_0-rmse:0.663403\n",
      "[28]\tvalidation_0-rmse:0.660131\n",
      "[29]\tvalidation_0-rmse:0.657075\n",
      "[30]\tvalidation_0-rmse:0.654331\n",
      "[31]\tvalidation_0-rmse:0.651551\n",
      "[32]\tvalidation_0-rmse:0.648896\n",
      "[33]\tvalidation_0-rmse:0.646355\n",
      "[34]\tvalidation_0-rmse:0.643931\n",
      "[35]\tvalidation_0-rmse:0.641659\n",
      "[36]\tvalidation_0-rmse:0.639572\n",
      "[37]\tvalidation_0-rmse:0.637630\n",
      "[38]\tvalidation_0-rmse:0.635704\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "\n",
    "depth = 15\n",
    "estimator = 150\n",
    "l_rate = 0.03\n",
    "sub_sample = 0.94\n",
    "col_sample = 0.85\n",
    "seed_val = 4242\n",
    "alpha_val = 1.0\n",
    "lambda_val = 1.0\n",
    "min_child_val = 15\n",
    "\n",
    "# Split For Validation\n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train, test_size=0.1)\n",
    "\n",
    "# Split for Train Test\n",
    "X_fit, X_eval, y_fit, y_eval= train_test_split(X_tr, y_tr, test_size=0.2)\n",
    "\n",
    "# classifier XBG Regression\n",
    "clf = xgb.XGBRegressor(missing=np.nan, \n",
    "                       max_depth=depth,\n",
    "                       n_estimators=estimator, \n",
    "                       learning_rate=l_rate,\n",
    "                       nthread=8, \n",
    "                       subsample=sub_sample,\n",
    "                       colsample_bytree=col_sample, \n",
    "                       seed=seed_val, \n",
    "                       reg_alpha = alpha_val,\n",
    "                       reg_lambda = lambda_val,\n",
    "                       min_child_weight=min_child_val\n",
    "                      )\n",
    "\n",
    "\n",
    "\n",
    "# fitting\n",
    "clf.fit(X_fit, y_fit, early_stopping_rounds=20, eval_metric=\"rmse\", eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "# predicting\n",
    "y_pred= clf.predict(X_test)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters\n",
      "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train, test_size=0.1\n",
      "\n",
      "Depth:  15\n",
      "estimator:  150\n",
      "l_rate:  0.03\n",
      "sub_sample:  0.94\n",
      "col_sample:  0.85\n",
      "seed:  4242\n",
      "Alpha:  1.0\n",
      "Lambda:  1.0\n",
      "Min Child:  20\n",
      "\n",
      "\n",
      " -- Scores -- Full Train -- \n",
      "Explained Variance Score:  0.801031481762\n",
      "Mean Absolute Error:  0.215141688128\n",
      "Mean Squared Error:  0.138554203811\n",
      "Median Absolute Error:  0.11531512912\n",
      "R2 Score:  0.801021244244\n",
      "\n",
      "\n",
      " -- Scores -- Train Split -- \n",
      "Explained Variance Score:  0.91575278827\n",
      "Mean Absolute Error:  0.155976291801\n",
      "Mean Squared Error:  0.0581680960815\n",
      "Median Absolute Error:  0.0985507144112\n",
      "R2 Score:  0.915742899699\n",
      "\n",
      "\n",
      " -- Scores -- Test Split -- \n",
      "Explained Variance Score:  0.512851195585\n",
      "Mean Absolute Error:  0.365787057814\n",
      "Mean Squared Error:  0.344478395748\n",
      "Median Absolute Error:  0.203173100564\n",
      "R2 Score:  0.512846975055\n",
      "\n",
      " -- Scores -- Validation -- \n",
      "Explained Variance Score:  0.518281667462\n",
      "Mean Absolute Error:  0.369970876249\n",
      "Mean Squared Error:  0.346670633978\n",
      "Median Absolute Error:  0.201939021016\n",
      "R2 Score:  0.518249945501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Print Parameters\n",
    "print(\"Parameters\")\n",
    "print(\"X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train, test_size=0.1\")\n",
    "print()\n",
    "print(\"Depth: \", depth)\n",
    "print(\"estimator: \", estimator)\n",
    "print(\"l_rate: \", l_rate)\n",
    "print(\"sub_sample: \", sub_sample)\n",
    "print(\"col_sample: \", col_sample)\n",
    "print(\"seed: \", seed_val)\n",
    "print(\"Alpha: \", alpha_val)\n",
    "print(\"Lambda: \", lambda_val)\n",
    "print(\"Min Child: \",min_child_val)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "# Score On Full Train Set\n",
    "full_train_pred = clf.predict(X_train)\n",
    "print(\" -- Scores -- Full Train -- \")\n",
    "print(\"Explained Variance Score: \", explained_variance_score(y_train, full_train_pred ))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_train, full_train_pred))\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_train, full_train_pred))\n",
    "print(\"Median Absolute Error: \", median_absolute_error(y_train, full_train_pred))\n",
    "print(\"R2 Score: \", r2_score(y_train, full_train_pred))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Score On Train Split\n",
    "split_train_pred = clf.predict(X_fit)\n",
    "print(\" -- Scores -- Train Split -- \")\n",
    "print(\"Explained Variance Score: \", explained_variance_score(y_fit, split_train_pred ))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_fit, split_train_pred))\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_fit, split_train_pred))\n",
    "print(\"Median Absolute Error: \", median_absolute_error(y_fit, split_train_pred))\n",
    "print(\"R2 Score: \", r2_score(y_fit, split_train_pred))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Score On Test Split\n",
    "split_test_pred = clf.predict(X_eval)\n",
    "print(\" -- Scores -- Test Split -- \")\n",
    "print(\"Explained Variance Score: \", explained_variance_score(y_eval, split_test_pred ))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_eval, split_test_pred))\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_eval, split_test_pred))\n",
    "print(\"Median Absolute Error: \", median_absolute_error(y_eval, split_test_pred))\n",
    "print(\"R2 Score: \", r2_score(y_eval, split_test_pred))\n",
    "print()\n",
    "\n",
    "# Score On Validation Data\n",
    "val_pred = clf.predict(X_val)\n",
    "print(\" -- Scores -- Validation -- \")\n",
    "print(\"Explained Variance Score: \", explained_variance_score(y_val, val_pred ))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_val, val_pred))\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_val, val_pred))\n",
    "print(\"Median Absolute Error: \", median_absolute_error(y_val, val_pred))\n",
    "print(\"R2 Score: \", r2_score(y_val, val_pred))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score on Test File From 9th Place Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "# Write To File\n",
    "import csv\n",
    "\n",
    "write_file = open('predictions_1.csv', 'w')\n",
    "write_file.write('ID,Prediction\\n')\n",
    "for x,y in enumerate(y_pred):\n",
    "    write_file.write('{},{} \\n'.format(x+1, y))\n",
    "    \n",
    "                     \n",
    "write_file.close()\n",
    "\n",
    "print(y_pred.shape)\n",
    "\n",
    "print('Completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
